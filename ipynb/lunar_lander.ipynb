{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gym.wrappers import RecordVideo\n",
    "from IPython import display\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.distributions import Categorical\n",
    "from tqdm.notebook import tqdm\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingLR\n",
    "# https://speech.ee.ntu.edu.tw/~hylee/ml/ml2021-course-data/hw/HW12/HW12_EN.pdf\n",
    "# https://github.com/john-hu/rl\n",
    "# https://medium.com/no-sliver-bullet/%E5%BC%B7%E5%8C%96%E5%AD%B8%E7%BF%92-reinforcement-learning-lunar-lander-v2-1291d48b71c3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix(env, seed):\n",
    "    # -deprecated- env.seed(seed)\n",
    "    env.reset(seed=seed)\n",
    "    env.action_space.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed = seed\n",
    "    # -deprecated- torch.set_deterministic(True)\n",
    "    torch.use_deterministic_algorithms = True\n",
    "    torch.are_deterministic_algorithms_enabled = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "\n",
    "seed = 543\n",
    "env = gym.make('LunarLander-v2', \n",
    "               render_mode='rgb_array')\n",
    "fix(env, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r-2.1055, total_reward:-24.7789, terminated:False\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset()\n",
    "img = plt.imshow(env.render()) # only call this once\n",
    "total_reward = 0\n",
    "for _ in range(100):\n",
    "    img.set_data(env.render()) # just update the data\n",
    "    display.display(plt.gcf())\n",
    "    display.clear_output(wait=True)\n",
    "    action = env.action_space.sample()\n",
    "    observation, reward, terminated, truncated, info = env.step(action)\n",
    "    total_reward += reward\n",
    "    print(f'\\r{reward:.4f}, total_reward:{total_reward:.4f}, terminated:{terminated}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# env.observation_space\n",
    "# env.action_space\n",
    "# initial_state, initial_info = env.reset(seed=seed)\n",
    "# random_action = env.action_space.sample()\n",
    "# observation, reward, terminated, truncated, info = env.step(random_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import gymnasium as gym\n",
    "# env = gym.make(\"LunarLander-v2\", render_mode=\"rgb_array\")\n",
    "# trigger = lambda t: t % 10 == 0\n",
    "# env = RecordVideo(env, video_folder=\"./video/video1\", episode_trigger=trigger, disable_logger=True)\n",
    "# for i in range(50):\n",
    "#     termination, truncation = False, False\n",
    "#     _ = env.reset(seed=123)\n",
    "#     while not (termination or truncation):\n",
    "#         obs, rew, termination, truncation, info = env.step(env.action_space.sample())\n",
    "\n",
    "# env.close()\n",
    "# len(os.listdir(\"./video/video1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demo_run(env, agent, seed=seed, num_episode=1, record_video=False, video_folder = './video/tmp', greedy=False):\n",
    "    agent.network.eval()\n",
    "    \n",
    "    if not record_video:\n",
    "        img = plt.imshow(env.render())\n",
    "    \n",
    "    for episode in range(num_episode):\n",
    "        if not record_video:\n",
    "            env_ = env\n",
    "        else:\n",
    "            trigger = lambda t: t%10 == 0\n",
    "            action_mode = 'greedy' if greedy else 'sample'\n",
    "            env_ = RecordVideo(env, video_folder=video_folder+f'-{action_mode}-{episode}', episode_trigger=trigger)\n",
    "            \n",
    "        state, info = env_.reset(seed=seed)\n",
    "        terminated, truncated = False, False\n",
    "        while not (terminated or truncated):\n",
    "            action, log_prob = agent.sample(state, greedy)\n",
    "            next_state, reward, terminated, truncated, info = env_.step(action)\n",
    "            state = next_state\n",
    "\n",
    "            if not record_video:\n",
    "                img.set_data(env.render())\n",
    "                display.display(plt.gcf())\n",
    "                display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gym.wrappers import RecordVideo\n",
    "# env = gym.make('LunarLander-v2', \n",
    "#                render_mode='rgb_array')\n",
    "# env.reset(seed=seed)\n",
    "# #img = plt.imshow(env.render())\n",
    "# trigger = lambda t: t % 100 == 0\n",
    "# env = RecordVideo(env, video_folder=\"./video/video3\", episode_trigger=trigger)\n",
    "\n",
    "# terminated, truncated = False, False\n",
    "# while not (terminated or truncated):\n",
    "#     action = env.action_space.sample()\n",
    "#     # observation, reward, done, _ \n",
    "#     observation, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "#     #img.set_data(env.render())\n",
    "#     #display.display(plt.gcf())\n",
    "#     #display.clear_output(wait=True)\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Policy Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8, 16)\n",
    "        self.fc2 = nn.Linear(16,16)\n",
    "        self.fc3 = nn.Linear(16, 4)\n",
    "\n",
    "    # def forward(self, state):\n",
    "    #     hid = torch.tanh(self.fc1(state))\n",
    "    #     hid = torch.tanh(self.fc2(hid))\n",
    "    #     return F.softmax(self.fc3(hid), dim=-1)\n",
    "\n",
    "    def forward(self, state):\n",
    "        hid = torch.relu(self.fc1(state))\n",
    "        hid = torch.relu(self.fc2(hid))\n",
    "        return F.softmax(self.fc3(hid), dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we need to build a simple agent. The agent will acts according to the output of the policy network above. There are a few things can be done by agent:\n",
    "\n",
    "* `learn()`：update the policy network from log probabilities and rewards.\n",
    "* `sample()`：After receiving observation from the environment, utilize policy network to tell which action to take. The return values of this function includes action and log probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PolicyGradientAgent():\n",
    "    def __init__(self, network, lr=1e-3, epochs=500):\n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.network = network\n",
    "        self.optimizer = optim.SGD(self.network.parameters(), lr=1e-3)\n",
    "        self.lr_scheduler = CosineAnnealingLR(self.optimizer, self.epochs, eta_min=1e-6)\n",
    "\n",
    "    def forward(self, state):\n",
    "        return self.network(state)\n",
    "\n",
    "    def learn(self, log_probs, rewards):\n",
    "        loss = (-log_probs * rewards).sum() # You don't need to revise this to pass simple baseline (but you can)\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()\n",
    "        self.lr_scheduler.step()\n",
    "        \n",
    "    def sample(self, state, greedy=False):\n",
    "        action_prob = self.network(torch.FloatTensor(np.array(state)))\n",
    "        action_dist = Categorical(action_prob)\n",
    "        if not greedy:\n",
    "            action = action_dist.sample()\n",
    "        else:\n",
    "            action = action_prob.argmax()\n",
    "        log_prob = action_dist.log_prob(action)\n",
    "        return action.item(), log_prob\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # build a network and agent to start training\n",
    "# network = PolicyGradientNetwork()\n",
    "# agent = PolicyGradientAgent(network)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# import random\n",
    "\n",
    "# # start a new wandb run to track this script\n",
    "# wandb.init(\n",
    "#     # set the wandb project where this run will be logged\n",
    "#     project=\"lunalander\",\n",
    "    \n",
    "#     # track hyperparameters and run metadata\n",
    "#     config={\n",
    "#     \"Agent\": \"PolicyGradientAgent\",\n",
    "#     \"reward\": \"normalized(step_reward)*step_log_prob\",\n",
    "#     \"learning_rate\": 1e-3,\n",
    "#     \"epochs\": 500,\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "\n",
    "config = {\"reward\":\"MC\"}\n",
    "\n",
    "agent.network.train()  # Switch network into training mode \n",
    "EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
    "NUM_BATCH = 10        # totally update the agent for 400 time\n",
    "gamma = 0.9\n",
    "\n",
    "avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "\n",
    "NUM_BATCH=1\n",
    "EPISODE_PER_BATCH = 1\n",
    "prg_bar = tqdm(range(NUM_BATCH))\n",
    "\n",
    "    \n",
    "for batch in range(NUM_BATCH):#prg_bar:\n",
    "    log_probs, rewards = [], []\n",
    "    total_rewards, final_rewards = [], []\n",
    "    total_steps = []\n",
    "    \n",
    "    # collect trajectory\n",
    "    for episode in range(EPISODE_PER_BATCH):\n",
    "        \n",
    "        state, info = env.reset()\n",
    "        img = plt.imshow(env.render())\n",
    "        total_reward, total_step = 0, 0\n",
    "        terminated, truncated = False, False\n",
    "        while not(terminated or truncated):\n",
    "        # while not (terminated or truncated):\n",
    "            print(f'\\r{reward:.4f}, total_reward:{total_reward:.4f}, terminated:{terminated}')\n",
    "            action, log_prob = agent.sample(state) # at, log(at|st)\n",
    "            next_state, reward, terminated, truncated, info = env.step(action)\n",
    "\n",
    "            # render\n",
    "            img.set_data(env.render()) # just update the data\n",
    "            display.display(plt.gcf())\n",
    "            display.clear_output(wait=True)     \n",
    "            # render       \n",
    "\n",
    "            log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
    "            state = next_state\n",
    "            total_reward += reward\n",
    "            match config[\"reward\"]:\n",
    "                case \"normalized_step_reward\":\n",
    "                    rewards.append(reward) # change here\n",
    "                case \"MC\":\n",
    "                    rewards.append(reward*(gamma**total_step))\n",
    "    \n",
    "            total_step += 1\n",
    "\n",
    "            # ! IMPORTANT !\n",
    "            # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n",
    "            #                                                         rewards :     r1, r2 ,r3 ......\n",
    "            # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n",
    "            #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n",
    "            # boss : implement Actor-Critic\n",
    "\n",
    "            # if terminated or truncated:\n",
    "            #    final_rewards.append(reward)\n",
    "            #    total_rewards.append(total_reward)\n",
    "            #    break\n",
    "\n",
    "        else:\n",
    "            final_rewards.append(reward)\n",
    "            total_rewards.append(total_reward)\n",
    "            total_steps.append(total_step)\n",
    "            state, info = env.reset()\n",
    "            #img.set_data(env.render()) # just update the data\n",
    "            #display.display(plt.gcf())\n",
    "            #display.clear_output(wait=True)     \n",
    "        \n",
    "    \n",
    "    # update agent\n",
    "    mean_rewards = np.mean(rewards)\n",
    "    std_rewards = np.std(rewards)\n",
    "\n",
    "    match config[\"reward\"]:\n",
    "        case \"normalized_step_reward\":\n",
    "            rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n",
    "        case \"MC\":\n",
    "            rewards_ = []\n",
    "            start = [sum(total_steps[:i]) for i in range(len(total_steps))]\n",
    "            end =  [sum(total_steps[:i]) for i in range(1, len(total_steps)+1)]\n",
    "\n",
    "            for s, e in zip(start, end):\n",
    "                rewards_ = rewards_ + [ sum(rewards[s:e][i:])/(gamma**i) for i in range(len(rewards[s:e])) ]\n",
    "            \n",
    "            #rewards = rewards_\n",
    "            #rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)\n",
    "    \n",
    "\n",
    "    #print(f\"rewards looks like \", np.shape(rewards))  \n",
    "    #print(f\"log_probs looks like \", np.shape(log_probs))     \n",
    "    # record training process\n",
    "    avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "    avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "    avg_total_rewards.append(avg_total_reward)\n",
    "    avg_final_rewards.append(avg_final_reward)\n",
    "    prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
    "\n",
    "    # update agent\n",
    "    # rewards = np.concatenate(rewards, axis=0)\n",
    "    mean_rewards = np.mean(rewards)\n",
    "    std_rewards = np.std(rewards)\n",
    "    # rewards = (np.array(rewards) - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n",
    "    #rewards = np.array(np.sum(rewards))\n",
    "    #rewards = np.array([sum(rewards[i:])/(gamma**i) for i in range(len(rewards))])\n",
    "    agent.learn(torch.stack(log_probs), torch.from_numpy(np.array(rewards_)))\n",
    "    # print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
    "    # print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy( np.array(rewards_) ).size())\n",
    "    \n",
    "    # wandb.log({\"mean rewards\":mean_rewards, \n",
    "    #            \"std reward\":std_rewards, \n",
    "    #            \"avg_total_reward\": avg_total_reward, \n",
    "    #            \"avg_final_reward\": avg_final_reward, \n",
    "    #            \"avg_episode_steps\":len(rewards)/EPISODE_PER_BATCH}\n",
    "    # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
    "NUM_BATCH = 500        # totally update the agent for 400 time\n",
    "\n",
    "def agent_run(\n",
    "    env, \n",
    "    agent, \n",
    "    config, \n",
    "    episode_per_batch=EPISODE_PER_BATCH, \n",
    "    num_batch=NUM_BATCH, \n",
    "    gamma=0.99,\n",
    "    step_punish = -0.15,\n",
    "    wandb_log = True,\n",
    "    verbose = False\n",
    "):\n",
    "\n",
    "    if wandb_log:\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project = config['project'], \n",
    "            # track hyperparameters and run metadata\n",
    "            config = config\n",
    "        )\n",
    "\n",
    "    match config['phase']:\n",
    "        case 'train':\n",
    "            agent.network.train()  # Switch network into training mode \n",
    "        case 'eval':\n",
    "            agent.network.eval()  # Switch network into eval mode \n",
    "    \n",
    "    num_batch, episode_per_batch = config['num_batch'], config['episode_per_batch']\n",
    "    avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "    prg_bar = tqdm(range(num_batch))\n",
    "    for batch in prg_bar:\n",
    "\n",
    "        log_probs, rewards = [], []\n",
    "        total_rewards, final_rewards = [], []\n",
    "        total_steps = []\n",
    "        # collect trajectory\n",
    "        for episode in range(episode_per_batch):\n",
    "            \n",
    "            state, info = env.reset()\n",
    "            total_reward, total_step = 0, 0\n",
    "            terminated, truncated = False, False\n",
    "            \n",
    "            while not(terminated or truncated):\n",
    "            # while not (terminated or truncated):\n",
    "                action, log_prob = agent.sample(state) # at, log(at|st)\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                reward += step_punish\n",
    "                # if reward == -100:\n",
    "                #     reward = -10\n",
    "                \n",
    "\n",
    "                log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                match config[\"reward\"]:\n",
    "                    case \"normalized_step_reward\":\n",
    "                        rewards.append(reward) # change here\n",
    "                    case \"MC\":\n",
    "                        rewards.append(reward*(gamma**total_step))\n",
    "                \n",
    "                total_step += 1\n",
    "                # ! IMPORTANT !\n",
    "                # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n",
    "                #                                                         rewards :     r1, r2 ,r3 ......\n",
    "                # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n",
    "                #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n",
    "                # boss : implement Actor-Critic\n",
    "\n",
    "                # if terminated or truncated:\n",
    "                #    final_rewards.append(reward)\n",
    "                #    total_rewards.append(total_reward)\n",
    "                #    break\n",
    "\n",
    "            else:\n",
    "                final_rewards.append(reward)\n",
    "                total_rewards.append(total_reward)\n",
    "                total_steps.append(total_step)\n",
    "                \n",
    "            \n",
    "\n",
    "        # record training process\n",
    "        avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "        avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "        avg_total_rewards.append(avg_total_reward)\n",
    "        avg_final_rewards.append(avg_final_reward)\n",
    "        avg_episode_steps = sum(total_steps)/len(total_steps)\n",
    "        prg_bar.set_description(f\"\\r Total reward: {avg_total_reward: 4.1f}, Final reward: {avg_final_reward: 4.1f}\")\n",
    "\n",
    "        # update agent\n",
    "        mean_rewards = np.mean(rewards)\n",
    "        std_rewards = np.std(rewards)\n",
    "\n",
    "        match config[\"reward\"]:\n",
    "            case \"normalized_step_reward\":\n",
    "                rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n",
    "            case \"MC\":\n",
    "                rewards_ = []\n",
    "                start = [sum(total_steps[:i]) for i in range(len(total_steps))]\n",
    "                end =  [sum(total_steps[:i]) for i in range(1, len(total_steps)+1)]\n",
    "\n",
    "                for s, e in zip(start, end):\n",
    "                    rewards_ = rewards_ + [ sum(rewards[s:e][i:])/(gamma**i) for i in range(len(rewards[s:e])) ]\n",
    "                \n",
    "                rewards = rewards_\n",
    "                rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)\n",
    "        \n",
    "                #rewards = np.array([sum(rewards[i:])/(gamma**i) for i in range(len(rewards))])\n",
    "                #rewards = np.array(np.sum(rewards))\n",
    "\n",
    "        agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
    "        if verbose:\n",
    "            print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
    "            print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())\n",
    "\n",
    "        if wandb_log:\n",
    "            wandb.log({\"mean rewards\":mean_rewards, \n",
    "                    \"std reward\":std_rewards, \n",
    "                    \"avg_total_reward\": avg_total_reward, \n",
    "                    \"avg_final_reward\": avg_final_reward, \n",
    "                    \"avg_episode_steps\":avg_episode_steps}\n",
    "            )\n",
    "\n",
    "    match config['phase']:\n",
    "        case 'train':\n",
    "            torch.save(agent.network.state_dict(), config['output_dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:fsi81gqz) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f25e1c025f42ca90af048894c59c10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.004 MB of 0.004 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_episode_steps</td><td>▁</td></tr><tr><td>avg_final_reward</td><td>▁</td></tr><tr><td>avg_total_reward</td><td>▁</td></tr><tr><td>mean rewards</td><td>▁</td></tr><tr><td>std reward</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_episode_steps</td><td>82.4</td></tr><tr><td>avg_final_reward</td><td>-100.0</td></tr><tr><td>avg_total_reward</td><td>-225.74438</td></tr><tr><td>mean rewards</td><td>-1.50772</td></tr><tr><td>std reward</td><td>5.7599</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">serene-valley-46</strong> at: <a href='http://140.112.31.147:8080/irlab/lunalander/runs/fsi81gqz' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander/runs/fsi81gqz</a><br/>Synced 4 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240310_093501-fsi81gqz/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Upgrade to the 0.50.2 version of W&B Server to get the latest features. Learn more: <a href='https://wandb.me/server-upgrade' target=\"_blank\">https://wandb.me/server-upgrade</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:fsi81gqz). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/github/openai-gym/wandb/run-20240310_100623-3wsfjbss</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://140.112.31.147:8080/irlab/lunalander/runs/3wsfjbss' target=\"_blank\">breezy-paper-47</a></strong> to <a href='http://140.112.31.147:8080/irlab/lunalander' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://140.112.31.147:8080/irlab/lunalander' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://140.112.31.147:8080/irlab/lunalander/runs/3wsfjbss' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander/runs/3wsfjbss</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "394362752bf743d9b125355966c85f2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "EPISODE_PER_BATCH = 5  # update the  agent every 5 episode\n",
    "NUM_BATCH = 1        # totally update the agent for 400 time\n",
    "\n",
    "# def agent_run(\n",
    "#     env, \n",
    "#     agent, \n",
    "#     config, \n",
    "#     episode_per_batch=EPISODE_PER_BATCH, \n",
    "#     num_batch=NUM_BATCH, \n",
    "#     gamma=0.99,\n",
    "#     wandb_log = True,\n",
    "#     verbose = False\n",
    "# ):\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"MC\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 1,\n",
    "    \"episode_per_batch\": 5,\n",
    "    \"output_dir\": \"./models/policy_gradient_normalized_step_reward\"\n",
    "}\n",
    "episode_per_batch=EPISODE_PER_BATCH \n",
    "num_batch=NUM_BATCH\n",
    "gamma=0.99\n",
    "wandb_log = True\n",
    "verbose = False\n",
    "\n",
    "if True:\n",
    "\n",
    "    if wandb_log:\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project = config['project'], \n",
    "            # track hyperparameters and run metadata\n",
    "            config = config\n",
    "        )\n",
    "\n",
    "    match config['phase']:\n",
    "        case 'train':\n",
    "            agent.network.train()  # Switch network into training mode \n",
    "        case 'eval':\n",
    "            agent.network.eval()  # Switch network into eval mode \n",
    "    \n",
    "    num_batch, episode_per_batch = config['num_batch'], config['episode_per_batch']\n",
    "    avg_total_rewards, avg_final_rewards = [], []\n",
    "\n",
    "    prg_bar = tqdm(range(num_batch))\n",
    "    for batch in prg_bar:\n",
    "\n",
    "        log_probs, rewards = [], []\n",
    "        total_rewards, final_rewards = [], []\n",
    "        total_steps = []\n",
    "        original_rewards = []\n",
    "        # collect trajectory\n",
    "        for episode in range(episode_per_batch):\n",
    "            \n",
    "            state, info = env.reset()\n",
    "            total_reward, total_step = 0, 0\n",
    "            terminated, truncated = False, False\n",
    "            \n",
    "            while not(terminated or truncated):\n",
    "            # while not (terminated or truncated):\n",
    "                action, log_prob = agent.sample(state) # at, log(at|st)\n",
    "                next_state, reward, terminated, truncated, info = env.step(action)\n",
    "                \n",
    "\n",
    "                log_probs.append(log_prob) # [log(a1|s1), log(a2|s2), ...., log(at|st)]\n",
    "                state = next_state\n",
    "                total_reward += reward\n",
    "                match config[\"reward\"]:\n",
    "                    case \"normalized_step_reward\":\n",
    "                        rewards.append(reward) # change here\n",
    "                    case \"MC\":\n",
    "                        rewards.append(reward*(gamma**total_step))\n",
    "                        original_rewards.append(reward)\n",
    "                \n",
    "                total_step += 1\n",
    "                # ! IMPORTANT !\n",
    "                # Current reward implementation: immediate reward,  given action_list : a1, a2, a3 ......\n",
    "                #                                                         rewards :     r1, r2 ,r3 ......\n",
    "                # medium：change \"rewards\" to accumulative decaying reward, given action_list : a1,                           a2,                           a3, ......\n",
    "                #                                                           rewards :           r1+0.99*r2+0.99^2*r3+......, r2+0.99*r3+0.99^2*r4+...... ,  r3+0.99*r4+0.99^2*r5+ ......\n",
    "                # boss : implement Actor-Critic\n",
    "\n",
    "                # if terminated or truncated:\n",
    "                #    final_rewards.append(reward)\n",
    "                #    total_rewards.append(total_reward)\n",
    "                #    break\n",
    "\n",
    "            else:\n",
    "                final_rewards.append(reward)\n",
    "                total_rewards.append(total_reward)\n",
    "                total_steps.append(total_step)\n",
    "                \n",
    "            \n",
    "\n",
    "        # record training process\n",
    "        avg_total_reward = sum(total_rewards) / len(total_rewards)\n",
    "        avg_final_reward = sum(final_rewards) / len(final_rewards)\n",
    "        avg_total_rewards.append(avg_total_reward)\n",
    "        avg_final_rewards.append(avg_final_reward)\n",
    "        avg_episode_steps = sum(total_steps)/len(total_steps)\n",
    "        prg_bar.set_description(f\"Total: {avg_total_reward: 4.1f}, Final: {avg_final_reward: 4.1f}\")\n",
    "\n",
    "        # update agent\n",
    "        mean_rewards = np.mean(rewards)\n",
    "        std_rewards = np.std(rewards)\n",
    "\n",
    "        match config[\"reward\"]:\n",
    "            case \"normalized_step_reward\":\n",
    "                rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)  # normalize the reward \n",
    "            case \"MC\":\n",
    "                rewards_ = []\n",
    "                start = [sum(total_steps[:i]) for i in range(len(total_steps))]\n",
    "                end =  [sum(total_steps[:i]) for i in range(1, len(total_steps)+1)]\n",
    "\n",
    "                for s, e in zip(start, end):\n",
    "                    rewards_ = rewards_ + [ sum(rewards[s:e][i:])/(gamma**i) for i in range(len(rewards[s:e])) ]\n",
    "                \n",
    "                rewards = np.array(rewards_)\n",
    "                #rewards = rewards_\n",
    "                #rewards = (rewards - np.mean(rewards)) / (np.std(rewards) + 1e-9)\n",
    "\n",
    "\n",
    "        agent.learn(torch.stack(log_probs), torch.from_numpy(rewards))\n",
    "        if verbose:\n",
    "            print(\"logs prob looks like \", torch.stack(log_probs).size())\n",
    "            print(\"torch.from_numpy(rewards) looks like \", torch.from_numpy(rewards).size())\n",
    "\n",
    "        if wandb_log:\n",
    "            wandb.log({\"mean rewards\":mean_rewards, \n",
    "                    \"std reward\":std_rewards, \n",
    "                    \"avg_total_reward\": avg_total_reward, \n",
    "                    \"avg_final_reward\": avg_final_reward, \n",
    "                    \"avg_episode_steps\":avg_episode_steps}\n",
    "            )\n",
    "\n",
    "    match config['phase']:\n",
    "        case 'train':\n",
    "            torch.save(agent.network.state_dict(), config['output_dir'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"normalized_step_reward\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 500,\n",
    "    \"episode_per_batch\": 5,\n",
    "    \"output_dir\": \"./models/policy_gradient_normalized_step_reward\"\n",
    "}\n",
    "\n",
    "agent_run(env, agent, config=config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "agent.network.load_state_dict(torch.load(config[\"output_dir\"]))\n",
    "\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_normalized_step_reward\", greedy=True)\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_normalized_step_reward\", greedy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:v29pz7d1) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf208b518dc549b3bddbf3c67c89d10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>avg_episode_steps</td><td>▁▁▁▂▂▁▂▁▂▂▂▂▂▂▂▂▂▅▂▃▅▂▃▃▂▂▃█▅▃▆▄▅▄▆▃▆▅▃▅</td></tr><tr><td>avg_final_reward</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁█▁█▄▁██▄▁█▁▁▄</td></tr><tr><td>avg_total_reward</td><td>▅▅▆▅▅▄▄▄▃▂▄▄▇▆▅▁▃▄▅▃▄▆▅▆▇▇▅▆▆▇▆▆▆█▇▆▆▆▆▇</td></tr><tr><td>mean rewards</td><td>▃▁▅▂▂▂▂▃▂▁▄▂▃▂▆▅▃▅▄▄▅▆▅▅█▆▅▅▆▆▅▅▆▅▆▆▆▆▆▆</td></tr><tr><td>std reward</td><td>▅▇▆██▆▇█▅▅▄▇▆▆▇▆▄▂▄▅▂▄▃▄▆▃▃▁▂▃▃▂▂▁▂▂▂▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>avg_episode_steps</td><td>293.2</td></tr><tr><td>avg_final_reward</td><td>-100.0</td></tr><tr><td>avg_total_reward</td><td>-88.1218</td></tr><tr><td>mean rewards</td><td>0.00639</td></tr><tr><td>std reward</td><td>0.0861</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">dandy-water-53</strong> at: <a href='http://140.112.31.147:8080/irlab/lunalander/runs/v29pz7d1' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander/runs/v29pz7d1</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20240310_112249-v29pz7d1/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Upgrade to the 0.50.2 version of W&B Server to get the latest features. Learn more: <a href='https://wandb.me/server-upgrade' target=\"_blank\">https://wandb.me/server-upgrade</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:v29pz7d1). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/jupyter/github/openai-gym/wandb/run-20240310_114024-l9bdo4hg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='http://140.112.31.147:8080/irlab/lunalander/runs/l9bdo4hg' target=\"_blank\">dainty-sun-54</a></strong> to <a href='http://140.112.31.147:8080/irlab/lunalander' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='http://140.112.31.147:8080/irlab/lunalander' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='http://140.112.31.147:8080/irlab/lunalander/runs/l9bdo4hg' target=\"_blank\">http://140.112.31.147:8080/irlab/lunalander/runs/l9bdo4hg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2942675a902647b984eafb02ecb11b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/rl-exp/lib/python3.10/site-packages/gymnasium/core.py:311: UserWarning: \u001b[33mWARN: env.is_vector_env to get variables from other wrappers is deprecated and will be removed in v1.0, to get this variable you can do `env.unwrapped.is_vector_env` for environment variables or `env.get_wrapper_attr('is_vector_env')` that will search the reminding wrappers.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Building video /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-greedy-0/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-greedy-0/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-greedy-0/rl-video-episode-0.mp4\n",
      "Moviepy - Building video /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-sample-0/rl-video-episode-0.mp4.\n",
      "Moviepy - Writing video /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-sample-0/rl-video-episode-0.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready /home/jupyter/github/openai-gym/video/policy_gradient_MC_gamma_0.7_advantage_step_punish-sample-0/rl-video-episode-0.mp4\n"
     ]
    }
   ],
   "source": [
    "# train\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"MC\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 500,\n",
    "    \"episode_per_batch\": 5,\n",
    "    \"output_dir\": \"./models/policy_gradient_MC_gamma_0.7\"\n",
    "}\n",
    "\n",
    "agent_run(env, agent, config=config, gamma=0.7)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "agent.network.load_state_dict(torch.load(config[\"output_dir\"]))\n",
    "\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.7_advantage_step_punish\", greedy=True)\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.7_advantage_step_punish\", greedy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"MC\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 500,\n",
    "    \"episode_per_batch\": 1,\n",
    "    \"output_dir\": \"./models/policy_gradient_MC_gamma_0.90\"\n",
    "}\n",
    "\n",
    "agent_run(env, agent, config=config, gamma=0.90)\n",
    "\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "agent.network.load_state_dict(torch.load(config[\"output_dir\"]))\n",
    "\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.90\", greedy=True)\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.90\", greedy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"MC\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 500,\n",
    "    \"episode_per_batch\": 5,\n",
    "    \"output_dir\": \"./models/policy_gradient_MC_gamma_0.90_episode_per_batch_5_normalized\"\n",
    "}\n",
    "\n",
    "agent_run(env, agent, config=config, gamma=0.90)\n",
    "\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "agent.network.load_state_dict(torch.load(config[\"output_dir\"]))\n",
    "\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_090_episode_per_batch_5_normalized\", greedy=True)\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_090_episode_per_batch_5_normalized\", greedy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "\n",
    "config={\n",
    "    \"agent\": \"PolicyGradientAgent\",\n",
    "    \"phase\": \"train\",\n",
    "    \"project\": \"lunalander\",\n",
    "    \"reward\": \"MC\",\n",
    "    \"learning_rate\": 1e-3,\n",
    "    \"num_batch\": 10000,\n",
    "    \"episode_per_batch\": 1,\n",
    "    \"output_dir\": \"./models/policy_gradient_MC_gamma_0.90\"\n",
    "}\n",
    "\n",
    "agent_run(env, agent, config=config, gamma=0.8)\n",
    "\n",
    "\n",
    "network = PolicyGradientNetwork()\n",
    "agent = PolicyGradientAgent(network)\n",
    "agent.network.load_state_dict(torch.load(config[\"output_dir\"]))\n",
    "\n",
    "env = gym.make('LunarLander-v2', render_mode='rgb_array')\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.90_batch_10000\", greedy=True)\n",
    "env.reset(seed=seed)\n",
    "demo_run(env, agent, seed=seed, record_video=True, video_folder = f\"./video/policy_gradient_MC_gamma_0.90_batch_10000\", greedy=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl-exp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
